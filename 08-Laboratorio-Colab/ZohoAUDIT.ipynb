{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKntBDq2nbhLWDPhu7myGe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cluciani-angel/grupo-angel-erp-core/blob/main/ZohoAUDIT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mf6G-fis4k_O",
        "outputId": "73ef59e0-eefb-4565-d8cc-1e24b8ecfb6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ **INFO:** INICIANDO PROCESO DE INGENIER√çA DE DATOS GRUPO ANGEL\n",
            "‚úÖ **INFO:** Escaneando archivos en ....\n",
            "‚úÖ **INFO:** Se detectaron 0 archivos para procesar.\n",
            "‚úÖ **INFO:** No se encontraron errores bloqueantes (¬°Incre√≠ble!).\n",
            "\n",
            "‚ú® PROCESO TERMINADO. Archivos generados:\n",
            " 1. AUDITORIA_DETALLADA_20251214_1744.csv (Data)\n",
            " 2. MEMORANDO_TECNICO_MIGRACION_20251214_1744.md (Reporte)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "import re\n",
        "from datetime import datetime\n",
        "\n",
        "# ==========================================\n",
        "# CONFIGURACI√ìN\n",
        "# ==========================================\n",
        "INPUT_FOLDER = '.'  # Carpeta actual en Colab\n",
        "TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
        "OUTPUT_CSV_NAME = f'AUDITORIA_DETALLADA_{TIMESTAMP}.csv'\n",
        "REPORT_FILE_NAME = f'MEMORANDO_TECNICO_MIGRACION_{TIMESTAMP}.md'\n",
        "\n",
        "# Listas para acumular hallazgos y narrativa del reporte\n",
        "audit_findings = []\n",
        "report_log = []\n",
        "\n",
        "def log_event(message, level=\"INFO\"):\n",
        "    \"\"\"Registra eventos para el reporte ejecutivo\"\"\"\n",
        "    icon = \"‚úÖ\" if level == \"INFO\" else (\"‚ö†Ô∏è\" if level == \"WARNING\" else \"üö®\")\n",
        "    entry = f\"{icon} **{level}:** {message}\"\n",
        "    report_log.append(entry)\n",
        "    print(entry)\n",
        "\n",
        "# ==========================================\n",
        "# 1. MOTOR DE DIAGN√ìSTICO\n",
        "# ==========================================\n",
        "\n",
        "log_event(\"INICIANDO PROCESO DE INGENIER√çA DE DATOS GRUPO ANGEL\", \"INFO\")\n",
        "log_event(f\"Escaneando archivos en {INPUT_FOLDER}...\", \"INFO\")\n",
        "\n",
        "csv_files = glob.glob(os.path.join(INPUT_FOLDER, \"*.csv\"))\n",
        "log_event(f\"Se detectaron {len(csv_files)} archivos para procesar.\", \"INFO\")\n",
        "\n",
        "for filename in csv_files:\n",
        "    try:\n",
        "        # Carga ligera inicial\n",
        "        df = pd.read_csv(filename, encoding='utf-8', on_bad_lines='skip', low_memory=False)\n",
        "        base_name = os.path.basename(filename)\n",
        "\n",
        "        # --- A. AUDITOR√çA DE ITEMS (PRODUCTOS/SERVICIOS) ---\n",
        "        if {'Item Name', 'SKU', 'Product Type'}.issubset(df.columns):\n",
        "            log_event(f\"Analizando Cat√°logo de Productos: {base_name}\", \"INFO\")\n",
        "\n",
        "            # 1. Check SKUs Inv√°lidos\n",
        "            def check_sku(x):\n",
        "                if pd.isna(x) or str(x).strip() == '': return 'MISSING'\n",
        "                if not re.match(r'^[A-Z0-9-]+$', str(x)): return 'INVALID_FORMAT'\n",
        "                return 'OK'\n",
        "\n",
        "            df['SKU_CHECK'] = df['SKU'].apply(check_sku)\n",
        "            bad_skus = df[df['SKU_CHECK'] != 'OK']\n",
        "\n",
        "            if not bad_skus.empty:\n",
        "                count = len(bad_skus)\n",
        "                log_event(f\"Detectados {count} Items con SKUs sucios o faltantes en {base_name}.\", \"WARNING\")\n",
        "                # Guardar detalle\n",
        "                for _, row in bad_skus.iterrows():\n",
        "                    audit_findings.append({\n",
        "                        'Archivo': base_name,\n",
        "                        'Tipo_Error': f'SKU_{row[\"SKU_CHECK\"]}',\n",
        "                        'Identificador': row['Item Name'],\n",
        "                        'Valor_Actual': row['SKU'],\n",
        "                        'Accion_Requerida': 'Sanitizar para SQL/Supabase',\n",
        "                        'Impacto': 'Alto (Rompe Sync)'\n",
        "                    })\n",
        "\n",
        "            # 2. Check Servicio con Inventario (Error Contable)\n",
        "            if 'Inventory Account Code' in df.columns:\n",
        "                services_with_stock = df[\n",
        "                    (df['Product Type'] == 'service') &\n",
        "                    (df['Inventory Account Code'].astype(str).str.startswith('1-', na=False))\n",
        "                ]\n",
        "                if not services_with_stock.empty:\n",
        "                    count = len(services_with_stock)\n",
        "                    log_event(f\"¬°CR√çTICO! {count} Servicios configurados err√≥neamente con cuenta de Inventario.\", \"ERROR\")\n",
        "                    for _, row in services_with_stock.iterrows():\n",
        "                        audit_findings.append({\n",
        "                            'Archivo': base_name,\n",
        "                            'Tipo_Error': 'CONTABILIDAD_MIXTA',\n",
        "                            'Identificador': row['Item Name'],\n",
        "                            'Valor_Actual': row['Inventory Account Code'],\n",
        "                            'Accion_Requerida': 'Cambiar a Tipo Goods o Quitar Cuenta Activo',\n",
        "                            'Impacto': 'Cr√≠tico (Infla Balance General)'\n",
        "                        })\n",
        "\n",
        "        # --- B. AUDITOR√çA CHART OF ACCOUNTS (CoA) ---\n",
        "        elif {'Account Code', 'Account Name'}.issubset(df.columns):\n",
        "            log_event(f\"Analizando Estructura Contable: {base_name}\", \"INFO\")\n",
        "\n",
        "            # Check Formato X-XXXX\n",
        "            def check_coa(x):\n",
        "                if pd.isna(x): return 'MISSING'\n",
        "                if not re.match(r'^\\d-\\d{4}$', str(x).strip()): return 'BAD_FORMAT'\n",
        "                return 'OK'\n",
        "\n",
        "            df['COA_CHECK'] = df['Account Code'].apply(check_coa)\n",
        "            bad_coa = df[df['COA_CHECK'] != 'OK']\n",
        "\n",
        "            if not bad_coa.empty:\n",
        "                log_event(f\"{len(bad_coa)} Cuentas contables no cumplen el est√°ndar X-XXXX.\", \"WARNING\")\n",
        "                for _, row in bad_coa.iterrows():\n",
        "                    audit_findings.append({\n",
        "                        'Archivo': base_name,\n",
        "                        'Tipo_Error': 'COA_FORMATO',\n",
        "                        'Identificador': row['Account Name'],\n",
        "                        'Valor_Actual': row['Account Code'],\n",
        "                        'Accion_Requerida': 'Renombrar C√≥digo para Consolidaci√≥n',\n",
        "                        'Impacto': 'Medio (Impide Reportes BI Unificados)'\n",
        "                    })\n",
        "\n",
        "    except Exception as e:\n",
        "        log_event(f\"Error procesando {filename}: {str(e)}\", \"ERROR\")\n",
        "\n",
        "# ==========================================\n",
        "# 2. GENERACI√ìN DE ENTREGABLES\n",
        "# ==========================================\n",
        "\n",
        "# A. CSV DE TRABAJO (T√©cnico)\n",
        "if audit_findings:\n",
        "    df_audit = pd.DataFrame(audit_findings)\n",
        "    df_audit.to_csv(OUTPUT_CSV_NAME, index=False)\n",
        "    log_event(f\"Generado CSV t√©cnico: {OUTPUT_CSV_NAME}\", \"INFO\")\n",
        "else:\n",
        "    log_event(\"No se encontraron errores bloqueantes (¬°Incre√≠ble!).\", \"INFO\")\n",
        "\n",
        "# B. REPORTE EJECUTIVO (Gerencial)\n",
        "with open(REPORT_FILE_NAME, 'w', encoding='utf-8') as f:\n",
        "    f.write(f\"# MEMORANDO T√âCNICO: MIGRACI√ìN ECOSISTEMA ZOHO - GRUPO ANGEL\\n\")\n",
        "    f.write(f\"**Fecha:** {datetime.now().strftime('%d/%m/%Y')}\\n\")\n",
        "    f.write(f\"**Responsable:** Arquitectura de Datos\\n\\n\")\n",
        "\n",
        "    f.write(\"## 1. OBJETIVO DEL PROCESO\\n\")\n",
        "    f.write(\"Asegurar que la data de las 8 filiales sea consistente para permitir la **Consolidaci√≥n Financiera Autom√°tica** y la sincronizaci√≥n con **Supabase/App M√≥vil**.\\n\\n\")\n",
        "\n",
        "    f.write(\"## 2. RESUMEN DE HALLAZGOS\\n\")\n",
        "    f.write(\"Se han analizado los archivos CSV maestros detectando las siguientes inconsistencias que requieren acci√≥n:\\n\\n\")\n",
        "    for line in report_log:\n",
        "        f.write(f\"{line}\\n\\n\")\n",
        "\n",
        "    f.write(\"## 3. BENEFICIOS DE ESTA LIMPIEZA\\n\")\n",
        "    f.write(\"* **Para Contabilidad:** Elimina el trabajo manual de 'cuadrar' reportes entre empresas. Unifica el Plan de Cuentas.\\n\")\n",
        "    f.write(\"* **Para Gerencia:** Permite Dashboards en Tiempo Real en Zoho Analytics sin errores de datos.\\n\")\n",
        "    f.write(\"* **Para Operaciones:** Evita errores en la App M√≥vil (Supabase) causados por SKUs con caracteres extra√±os.\\n\\n\")\n",
        "\n",
        "    f.write(\"## 4. SIGUIENTES PASOS\\n\")\n",
        "    f.write(f\"1. Descargar el archivo `{OUTPUT_CSV_NAME}`.\\n\")\n",
        "    f.write(\"2. Abrirlo en Google Sheets.\\n\")\n",
        "    f.write(\"3. Asignar responsables para corregir los items marcados como 'CR√çTICO'.\\n\")\n",
        "\n",
        "print(f\"\\n‚ú® PROCESO TERMINADO. Archivos generados:\\n 1. {OUTPUT_CSV_NAME} (Data)\\n 2. {REPORT_FILE_NAME} (Reporte)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ==============================================================================\n",
        "# üèóÔ∏è SCRIPT DE AUDITOR√çA Y GOBERNANZA DE DATOS - GRUPO ANGEL (MF WORLD)\n",
        "# ==============================================================================\n",
        "# AUTOR: ZBooks AI Architecture\n",
        "# PROP√ìSITO: Analizar lote masivo de CSVs de Zoho Books para migraci√≥n a Supabase.\n",
        "# SALIDA: 1. Excel con errores t√©cnicos (Data Cleaning).\n",
        "#         2. Reporte Markdown para Stakeholders (Gerencia/Contabilidad).\n",
        "# ==============================================================================\n"
      ],
      "metadata": {
        "id": "h3K2u7fKDuif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import glob\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "\n",
        "# 1Ô∏è‚É£ CONEXI√ìN CON GOOGLE DRIVE\n",
        "# ------------------------------------------------------------------------------\n",
        "# Esto monta tu Drive como si fuera un disco duro local.\n",
        "print(\"üîå Conectando a Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# üìÇ CONFIGURACI√ìN DE RUTAS (Ajusta si tu carpeta se llama diferente)\n",
        "BASE_PATH = '/content/drive/My Drive/MIGRACION_GRUPO_ANGEL'\n",
        "INPUT_PATH = os.path.join(BASE_PATH, 'INPUT_CSVS')\n",
        "OUTPUT_PATH = BASE_PATH # Los reportes se guardar√°n en la ra√≠z de la carpeta\n",
        "\n",
        "# Verificaci√≥n de seguridad\n",
        "if not os.path.exists(INPUT_PATH):\n",
        "    print(f\"‚ùå ERROR: No encuentro la carpeta {INPUT_PATH}\")\n",
        "    print(\"   Por favor crea la carpeta en Drive y sube los CSVs ah√≠.\")\n",
        "else:\n",
        "    print(f\"‚úÖ Carpeta encontrada. Iniciando escaneo en: {INPUT_PATH}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 2Ô∏è‚É£ L√ìGICA DE DETECCI√ìN INTELIGENTE (CEREBRO DEL SCRIPT)\n",
        "# ==============================================================================\n",
        "# Esta funci√≥n \"mira\" dentro de cada CSV para saber qu√© es (Factura, Item, Cuenta)\n",
        "# sin importar el nombre del archivo.\n",
        "\n",
        "def identify_file_type(df):\n",
        "    cols = set(df.columns)\n",
        "    # Huellas digitales de cada tipo de archivo en Zoho\n",
        "    if {'Item Name', 'SKU', 'Product Type'}.issubset(cols): return 'ITEMS'\n",
        "    if {'Account Code', 'Account Name'}.issubset(cols): return 'COA' # Chart of Accounts\n",
        "    if {'Invoice Number', 'Customer Name'}.issubset(cols): return 'INVOICES'\n",
        "    if {'Vendor Name', 'Bill Number'}.issubset(cols): return 'BILLS'\n",
        "    return 'OTHER'\n",
        "\n",
        "data_map = {}\n",
        "all_files = glob.glob(os.path.join(INPUT_PATH, \"*.csv\"))\n",
        "file_log = [] # Para el reporte\n",
        "\n",
        "print(f\"üîÑ Procesando {len(all_files)} archivos encontrados...\")\n",
        "\n",
        "for filename in all_files:\n",
        "    try:\n",
        "        # Leemos solo cabeceras primero para velocidad\n",
        "        df_preview = pd.read_csv(filename, nrows=2, encoding='utf-8', on_bad_lines='skip')\n",
        "        ftype = identify_file_type(df_preview)\n",
        "\n",
        "        if ftype != 'OTHER':\n",
        "            # Carga completa si es un archivo reconocido\n",
        "            df = pd.read_csv(filename, encoding='utf-8', on_bad_lines='skip', low_memory=False)\n",
        "            data_map[ftype] = df\n",
        "            file_log.append(f\"- **{os.path.basename(filename)}**: Identificado como `{ftype}` ({len(df)} registros).\")\n",
        "            print(f\"   -> {ftype}: {os.path.basename(filename)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ö†Ô∏è Error leyendo {filename}: {e}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 3Ô∏è‚É£ REGLAS DE NEGOCIO Y AUDITOR√çA (AQU√ç EST√Å LA INTELIGENCIA)\n",
        "# ==============================================================================\n",
        "\n",
        "audit_findings = {}\n",
        "stats = {'invalid_skus': 0, 'critical_errors': 0, 'coa_warnings': 0}\n",
        "\n",
        "# --- A. AUDITOR√çA DE ITEMS (SKU & TIPOLOG√çA) ---\n",
        "if 'ITEMS' in data_map:\n",
        "    df_items = data_map['ITEMS']\n",
        "\n",
        "    # 1. Validaci√≥n SKU (Solo May√∫sculas, N√∫meros y Guiones)\n",
        "    # Explicaci√≥n: SQL y Supabase odian espacios y caracteres especiales.\n",
        "    def check_sku(sku):\n",
        "        if pd.isna(sku) or str(sku).strip() == '': return 'FALTA_SKU'\n",
        "        if not re.match(r'^[A-Z0-9-]+$', str(sku)): return 'CARACTER_ILEGAL'\n",
        "        return 'OK'\n",
        "\n",
        "    df_items['ESTADO_SKU'] = df_items['SKU'].apply(check_sku)\n",
        "\n",
        "    # 2. Validaci√≥n Cruzada: ¬øServicios moviendo Inventario? (RED FLAG)\n",
        "    # Un servicio (mano de obra) nunca debe tener una cuenta de Activo (1-XXXX)\n",
        "    df_items['ERROR_CRITICO'] = False\n",
        "    if 'Inventory Account Code' in df_items.columns:\n",
        "        mask_service = df_items['Product Type'] == 'service'\n",
        "        # Asumimos que cuentas de inventario empiezan con '1' o '1-'\n",
        "        mask_inv_acc = df_items['Inventory Account Code'].astype(str).str.startswith(('1-', '15'), na=False)\n",
        "        df_items.loc[mask_service & mask_inv_acc, 'ERROR_CRITICO'] = True\n",
        "\n",
        "    # Filtrar errores para el Excel\n",
        "    errores_items = df_items[\n",
        "        (df_items['ESTADO_SKU'] != 'OK') | (df_items['ERROR_CRITICO'] == True)\n",
        "    ][['Item Name', 'SKU', 'Product Type', 'ESTADO_SKU', 'ERROR_CRITICO', 'Status']]\n",
        "\n",
        "    audit_findings['ERRORES_ITEMS'] = errores_items\n",
        "    stats['invalid_skus'] = len(df_items[df_items['ESTADO_SKU'] != 'OK'])\n",
        "    stats['critical_errors'] = len(df_items[df_items['ERROR_CRITICO'] == True])\n",
        "\n",
        "# --- B. AUDITOR√çA CONTABLE (CoA) ---\n",
        "if 'COA' in data_map:\n",
        "    df_coa = data_map['COA']\n",
        "    # Buscamos formatos inconsistentes (diferentes a X-XXXX)\n",
        "    def validate_coa(code):\n",
        "        if pd.isna(code): return 'SIN_CODIGO'\n",
        "        if not re.match(r'^\\d-\\d{4}$', str(code).strip()): return 'FORMATO_INCORRECTO'\n",
        "        return 'OK'\n",
        "\n",
        "    df_coa['REVISION'] = df_coa['Account Code'].apply(validate_coa)\n",
        "    audit_findings['ERRORES_COA'] = df_coa[df_coa['REVISION'] != 'OK'][['Account Name', 'Account Code', 'Account Type', 'REVISION']]\n",
        "    stats['coa_warnings'] = len(audit_findings['ERRORES_COA'])\n",
        "\n",
        "# ==============================================================================\n",
        "# 4Ô∏è‚É£ GENERACI√ìN DE SALIDAS (REPORTING)\n",
        "# ==============================================================================\n",
        "\n",
        "# A. Generar Excel Maestro (Para el equipo t√©cnico)\n",
        "excel_path = os.path.join(OUTPUT_PATH, 'AUDITORIA_TECNICA_ZOHO.xlsx')\n",
        "with pd.ExcelWriter(excel_path) as writer:\n",
        "    for sheet, df in audit_findings.items():\n",
        "        df.to_excel(writer, sheet_name=sheet, index=False)\n",
        "print(f\"\\nüíæ Excel T√©cnico generado: {excel_path}\")\n",
        "\n",
        "# B. Generar Reporte Narrativo Markdown (Para Gerencia/Stakeholders)\n",
        "md_path = os.path.join(OUTPUT_PATH, 'REPORTE_EJECUTIVO_MIGRACION.md')\n",
        "timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
        "\n",
        "markdown_content = f\"\"\"\n",
        "# üìë REPORTE DE INGENIER√çA DE DATOS: GRUPO ANGEL\n",
        "**Fecha:** {timestamp}\n",
        "**Origen:** Auditor√≠a Autom√°tica (Python ETL)\n",
        "**Alcance:** Validaci√≥n Pre-Migraci√≥n (Zoho Books -> Supabase)\n",
        "\n",
        "---\n",
        "\n",
        "## 1. RESUMEN EJECUTIVO\n",
        "Se ha realizado un escaneo profundo de la estructura de datos de **MF World S.A.** para garantizar la integridad en la migraci√≥n al nuevo ecosistema digital. El objetivo es transformar datos contables \"crudos\" en datos de ingenier√≠a listos para BigQuery.\n",
        "\n",
        "### üìä Hallazgos Principales\n",
        "* **Items Analizados:** {len(data_map.get('ITEMS', []))}\n",
        "* **SKUs Inv√°lidos/Faltantes:** {stats['invalid_skus']} (Requieren correcci√≥n para ser le√≠dos por SQL).\n",
        "* **Errores Cr√≠ticos de Configuraci√≥n:** {stats['critical_errors']} (Items de servicio que afectan inventario err√≥neamente).\n",
        "* **Cuentas Contables fuera de Est√°ndar:** {stats['coa_warnings']} (C√≥digos que no siguen el formato X-XXXX).\n",
        "\n",
        "---\n",
        "\n",
        "## 2. POR QU√â HICIMOS ESTO (BENEFICIOS)\n",
        "Este proceso de limpieza no es est√©tico, es **funcional**:\n",
        "1.  **Consolidaci√≥n Automatizada:** Al estandarizar los SKUs y Cuentas, podremos ver las ventas de las 8 empresas en un solo Dashboard en tiempo real.\n",
        "2.  **Prevenci√≥n de Errores Fiscales:** Detectamos servicios que estaban moviendo inventario (costo fantasma), evitando inconsistencias ante la DGI.\n",
        "3.  **Velocidad:** Una base de datos limpia en Supabase permitir√° que la futura App opere en milisegundos.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. ARCHIVOS PROCESADOS\n",
        "{chr(10).join(file_log)}\n",
        "\n",
        "---\n",
        "\n",
        "## 4. PR√ìXIMOS PASOS (PLAN DE ACCI√ìN)\n",
        "Revisar el archivo adjunto `AUDITORIA_TECNICA_ZOHO.xlsx` y ejecutar:\n",
        "1.  **Limpieza de SKUs:** Asignar c√≥digos a los items marcados como `FALTA_SKU`.\n",
        "2.  **Correcci√≥n Contable:** Modificar el item cr√≠tico detectado (ej: *Vivere Articulo Generico*) para que no afecte cuentas de inventario.\n",
        "3.  **Homologaci√≥n:** Ajustar el Cat√°logo de Cuentas al est√°ndar `X-XXXX`.\n",
        "\n",
        "*Reporte generado autom√°ticamente por ZBooks AI Architecture.*\n",
        "\"\"\"\n",
        "\n",
        "with open(md_path, \"w\", encoding='utf-8') as f:\n",
        "    f.write(markdown_content)\n",
        "\n",
        "print(f\"üìù Reporte Ejecutivo generado: {md_path}\")\n",
        "print(\"\\n‚úÖ ¬°PROCESO COMPLETADO! Ve a tu carpeta de Drive para ver los resultados.\")"
      ],
      "metadata": {
        "id": "0loCNgTI5g2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6Azu06Sg5hkR"
      }
    }
  ]
}